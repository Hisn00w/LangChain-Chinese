
# å¿«é€Ÿå…¥é—¨


---

æœ¬å¿«é€Ÿå…¥é—¨æŒ‡å—å°†å¸¦ä½ åœ¨**å‡ åˆ†é’Ÿå†…**ï¼Œä»ä¸€ä¸ªæœ€ç®€å•çš„é…ç½®ï¼Œæ„å»ºå‡ºä¸€ä¸ª**åŠŸèƒ½å®Œæ•´çš„ AI Agent**ã€‚

> ğŸ’¡ **LangChain Docs MCP Server**
>
> å¦‚æœä½ æ­£åœ¨ä½¿ç”¨ AI ç¼–ç¨‹åŠ©æ‰‹æˆ– IDEï¼ˆä¾‹å¦‚ Claude Codeã€Cursor ç­‰ï¼‰ï¼Œå»ºè®®å®‰è£…  
> [LangChain Docs MCP server](https://docs.langchain.com/use-these-docs)ã€‚  
> è¿™æ ·å¯ä»¥ç¡®ä¿ä½ çš„ Agent èƒ½è®¿é—®**æœ€æ–°çš„ LangChain æ–‡æ¡£ä¸ç¤ºä¾‹**ï¼Œè·å¾—æ›´å¥½çš„ä½¿ç”¨ä½“éªŒã€‚

---

## å‰ç½®è¦æ±‚

åœ¨å¼€å§‹ä¹‹å‰ï¼Œä½ éœ€è¦å®Œæˆä»¥ä¸‹å‡†å¤‡å·¥ä½œï¼š

- å®‰è£… LangChainï¼ˆè§ [Install](install.md)ï¼‰
- æ³¨å†Œä¸€ä¸ª [Claudeï¼ˆAnthropicï¼‰](https://www.anthropic.com/) è´¦å·å¹¶è·å– API Key
- åœ¨ç»ˆç«¯ä¸­è®¾ç½®ç¯å¢ƒå˜é‡ `ANTHROPIC_API_KEY`

å°½ç®¡ä¸‹é¢çš„ç¤ºä¾‹ä½¿ç”¨çš„æ˜¯ Claudeï¼Œä½ ä¹Ÿå¯ä»¥é€šè¿‡æ›´æ¢æ¨¡å‹åç§°å¹¶é…ç½®å¯¹åº”çš„ API Keyï¼Œæ¥ä½¿ç”¨  
[ä»»æ„å—æ”¯æŒçš„æ¨¡å‹](../integrations/providers/overview.md)ã€‚

---

## æ„å»ºä¸€ä¸ªåŸºç¡€ Agent

æˆ‘ä»¬å…ˆä»ä¸€ä¸ª**æœ€ç®€å•çš„ Agent**å¼€å§‹ã€‚  
è¿™ä¸ª Agent å¯ä»¥å›ç­”é—®é¢˜ï¼Œå¹¶è°ƒç”¨å·¥å…·ï¼š

- ä½¿ç”¨ **Claude Sonnet 4.5** ä½œä¸ºè¯­è¨€æ¨¡å‹
- ä½¿ç”¨ä¸€ä¸ªç®€å•çš„å¤©æ°”å‡½æ•°ä½œä¸ºå·¥å…·
- ä½¿ç”¨ä¸€ä¸ªåŸºç¡€çš„ system prompt å¼•å¯¼ Agent è¡Œä¸º

```python
from langchain.agents import create_agent

def get_weather(city: str) -> str:
    """Get weather for a given city."""
    return f"It's always sunny in {city}!"

agent = create_agent(
    model="claude-sonnet-4-5-20250929",
    tools=[get_weather],
    system_prompt="You are a helpful assistant",
)

# Run the agent
agent.invoke(
    {"messages": [{"role": "user", "content": "what is the weather in sf"}]}
)
````

> ğŸ’¡ å¦‚æœä½ æƒ³å­¦ä¹ å¦‚ä½•ä½¿ç”¨ LangSmith å¯¹ Agent è¿›è¡Œè¿½è¸ªä¸è°ƒè¯•ï¼Œ
> è¯·å‚é˜…ï¼š[LangSmith æ–‡æ¡£](https://docs.langchain.com/langsmith/trace-with-langchain)

---

## æ„å»ºç”Ÿäº§çº§ Agent

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†æ„å»ºä¸€ä¸ª**æ›´æ¥è¿‘çœŸå®ç”Ÿäº§åœºæ™¯çš„å¤©æ°”é¢„æŠ¥ Agent**ï¼Œå¹¶æ¶µç›–ä»¥ä¸‹å…³é”®æ¦‚å¿µï¼š

1. æ›´è¯¦ç»†çš„ **system prompt**
2. **å·¥å…·ï¼ˆToolsï¼‰** ä¸å¤–éƒ¨æ•°æ®çš„é›†æˆ
3. **æ¨¡å‹é…ç½®**ï¼Œä»¥è·å¾—æ›´ç¨³å®šçš„è¾“å‡º
4. **ç»“æ„åŒ–è¾“å‡ºï¼ˆStructured outputï¼‰**
5. **å¯¹è¯è®°å¿†ï¼ˆConversational memoryï¼‰**
6. åˆ›å»ºå¹¶è¿è¡Œä¸€ä¸ªå®Œæ•´çš„ Agent

ä¸‹é¢æˆ‘ä»¬ä¸€æ­¥ä¸€æ­¥æ¥ã€‚

---

### æ­¥éª¤ 1ï¼šå®šä¹‰ç³»ç»Ÿæç¤ºè¯

System prompt ç”¨äºå®šä¹‰ Agent çš„è§’è‰²ä¸è¡Œä¸ºï¼Œåº”å°½é‡å…·ä½“ã€å¯æ‰§è¡Œï¼š

```python
SYSTEM_PROMPT = """You are an expert weather forecaster, who speaks in puns.

You have access to two tools:

- get_weather_for_location: use this to get the weather for a specific location
- get_user_location: use this to get the user's location

If a user asks you for the weather, make sure you know the location.
If you can tell from the question that they mean wherever they are,
use the get_user_location tool to find their location."""
```

---

### æ­¥éª¤ 2ï¼šåˆ›å»ºå·¥å…·

[Tools](tools.md) å…è®¸æ¨¡å‹é€šè¿‡è°ƒç”¨ä½ å®šä¹‰çš„å‡½æ•°ï¼Œä¸å¤–éƒ¨ç³»ç»Ÿäº¤äº’ã€‚
å·¥å…·å¯ä»¥ä¾èµ– [runtime context](runtime.md)ï¼Œä¹Ÿå¯ä»¥ä¸
[agent memory](short-term-memory.md) ç»“åˆä½¿ç”¨ã€‚

ä¸‹é¢ç¤ºä¾‹å±•ç¤ºäº† `get_user_location` å¦‚ä½•ä½¿ç”¨ runtime contextï¼š

```python
from dataclasses import dataclass
from langchain.tools import tool, ToolRuntime

@tool
def get_weather_for_location(city: str) -> str:
    """Get weather for a given city."""
    return f"It's always sunny in {city}!"

@dataclass
class Context:
    """Custom runtime context schema."""
    user_id: str

@tool
def get_user_location(runtime: ToolRuntime[Context]) -> str:
    """Retrieve user information based on user ID."""
    user_id = runtime.context.user_id
    return "Florida" if user_id == "1" else "SF"
```

> ğŸ’¡ å·¥å…·éœ€è¦è‰¯å¥½çš„æ–‡æ¡£è¯´æ˜ï¼š
> å·¥å…·åã€æè¿°ã€å‚æ•°åéƒ½ä¼šæˆä¸ºæ¨¡å‹ prompt çš„ä¸€éƒ¨åˆ†ã€‚
> LangChain çš„ `@tool` è£…é¥°å™¨ä¼šè‡ªåŠ¨æ·»åŠ è¿™äº›å…ƒæ•°æ®ï¼Œå¹¶æ”¯æŒé€šè¿‡ `ToolRuntime` æ³¨å…¥è¿è¡Œæ—¶ä¸Šä¸‹æ–‡ã€‚

---

### æ­¥éª¤ 3ï¼šé…ç½®æ¨¡å‹

ä¸ºä½ çš„ç”¨ä¾‹é…ç½®åˆé€‚çš„ [è¯­è¨€æ¨¡å‹](models.md) å‚æ•°ï¼š

```python
from langchain.chat_models import init_chat_model

model = init_chat_model(
    "claude-sonnet-4-5-20250929",
    temperature=0.5,
    timeout=10,
    max_tokens=1000
)
```

ä¸åŒæ¨¡å‹ä¸æä¾›å•†æ”¯æŒçš„å‚æ•°å¯èƒ½ä¸åŒï¼Œè¯·å‚è€ƒå¯¹åº”çš„å‚è€ƒæ–‡æ¡£ã€‚

---

### æ­¥éª¤ 4ï¼šå®šä¹‰å“åº”æ ¼å¼

å¦‚æœä½ éœ€è¦ Agent çš„è¾“å‡ºç¬¦åˆå›ºå®šç»“æ„ï¼Œå¯ä»¥å®šä¹‰**ç»“æ„åŒ–å“åº”æ ¼å¼**ï¼š

```python
from dataclasses import dataclass

# ä½¿ç”¨ dataclassï¼›åŒæ ·ä¹Ÿæ”¯æŒ Pydantic
@dataclass
class ResponseFormat:
    """Response schema for the agent."""
    # å¿…é¡»è¿”å›çš„åŒå…³è¯­å›ç­”
    punny_response: str
    # å¯é€‰çš„å¤©æ°”è¡¥å……ä¿¡æ¯
    weather_conditions: str | None = None
```

---

### æ­¥éª¤ 5ï¼šæ·»åŠ è®°å¿†

ä¸º Agent æ·»åŠ  [è®°å¿†èƒ½åŠ›](short-term-memory.md)ï¼Œä»¥åœ¨å¤šè½®å¯¹è¯ä¸­ä¿æŒä¸Šä¸‹æ–‡çŠ¶æ€ï¼š

```python
from langgraph.checkpoint.memory import InMemorySaver

checkpointer = InMemorySaver()
```

> â„¹ï¸ åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œåº”ä½¿ç”¨**æŒä¹…åŒ–çš„ checkpointer**ï¼ˆä¾‹å¦‚æ•°æ®åº“ï¼‰ã€‚
> è¯¦è§ï¼š[Add and manage memory](https://docs.langchain.com/oss/python/langgraph/add-memory#manage-short-term-memory)

---

### æ­¥éª¤ 6ï¼šåˆ›å»ºå¹¶è¿è¡Œ Agent

ç°åœ¨ï¼Œå°†æ‰€æœ‰ç»„ä»¶ç»„åˆèµ·æ¥ï¼Œåˆ›å»ºå¹¶è¿è¡Œä¸€ä¸ªå®Œæ•´çš„ Agentï¼š

```python
from langchain.agents.structured_output import ToolStrategy

agent = create_agent(
    model=model,
    system_prompt=SYSTEM_PROMPT,
    tools=[get_user_location, get_weather_for_location],
    context_schema=Context,
    response_format=ToolStrategy(ResponseFormat),
    checkpointer=checkpointer
)

# thread_id ç”¨äºæ ‡è¯†ä¸€æ¬¡å¯¹è¯
config = {"configurable": {"thread_id": "1"}}

response = agent.invoke(
    {"messages": [{"role": "user", "content": "what is the weather outside?"}]},
    config=config,
    context=Context(user_id="1")
)

print(response["structured_response"])
```

ä½ å¯ä»¥ä½¿ç”¨ç›¸åŒçš„ `thread_id` ç»§ç»­å¯¹è¯ï¼š

```python
response = agent.invoke(
    {"messages": [{"role": "user", "content": "thank you!"}]},
    config=config,
    context=Context(user_id="1")
)

print(response["structured_response"])
```

---

## å®Œæ•´ç¤ºä¾‹ä»£ç 

> ä»¥ä¸‹æ˜¯å°†ä¸Šè¿°æ‰€æœ‰æ­¥éª¤æ•´åˆåœ¨ä¸€èµ·çš„å®Œæ•´ç¤ºä¾‹ä»£ç ï¼š

```python
from dataclasses import dataclass

from langchain.agents import create_agent
from langchain.chat_models import init_chat_model
from langchain.tools import tool, ToolRuntime
from langgraph.checkpoint.memory import InMemorySaver
from langchain.agents.structured_output import ToolStrategy


SYSTEM_PROMPT = """You are an expert weather forecaster, who speaks in puns.

You have access to two tools:

- get_weather_for_location
- get_user_location
"""

@dataclass
class Context:
    user_id: str

@tool
def get_weather_for_location(city: str) -> str:
    return f"It's always sunny in {city}!"

@tool
def get_user_location(runtime: ToolRuntime[Context]) -> str:
    return "Florida" if runtime.context.user_id == "1" else "SF"

model = init_chat_model(
    "claude-sonnet-4-5-20250929",
    temperature=0
)

@dataclass
class ResponseFormat:
    punny_response: str
    weather_conditions: str | None = None

checkpointer = InMemorySaver()

agent = create_agent(
    model=model,
    system_prompt=SYSTEM_PROMPT,
    tools=[get_user_location, get_weather_for_location],
    context_schema=Context,
    response_format=ToolStrategy(ResponseFormat),
    checkpointer=checkpointer
)
```

---

## æ­å–œä½  ğŸ‰

ç°åœ¨ä½ å·²ç»æ„å»ºäº†ä¸€ä¸ªèƒ½å¤Ÿï¼š

* **ç†è§£ä¸Šä¸‹æ–‡å¹¶è®°ä½å¯¹è¯**
* **æ™ºèƒ½ä½¿ç”¨å¤šä¸ªå·¥å…·**
* **ä»¥ç»“æ„åŒ–æ ¼å¼è¾“å‡ºç»“æœ**
* **å¤„ç†ç”¨æˆ·ä¸Šä¸‹æ–‡ä¿¡æ¯**
* **åœ¨å¤šè½®å¯¹è¯ä¸­ä¿æŒçŠ¶æ€**

çš„ AI Agentã€‚

